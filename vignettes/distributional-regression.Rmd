---
title: "Distributional Regression for Motorcycle Crash Data with Time-Varying Location and Scale Parameters"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Distributional Regression for Motorcycle Crash Data with Time-Varying Location and Scale Parameters}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)
```

```{r setup}
library(ffc)
library(mgcv)
library(MASS)
library(dplyr)
library(ggplot2)
theme_set(theme_bw())
```

## Introduction

Motorcycle crash dynamics involve complex patterns where both the mean acceleration and its variability change dramatically over time during impact events. Traditional Gaussian regression assumes constant variance, potentially missing critical safety insights about periods of extreme or unpredictable forces. This vignette demonstrates how distributional regression with the [`ffc`](https://github.com/njtierney/ffc) package addresses these challenges through:

1. Time-varying location parameters capturing evolving mean acceleration patterns  
2. Time-varying scale parameters modeling heteroskedasticity during impact phases    
3. Rolling forecast evaluation for robust model validation  
4. Comprehensive uncertainty quantification for safety applications  

### The crash dynamics challenge

Motorcycle crash acceleration data presents unique modeling challenges:

- Non-constant variance during different impact phases  
- Complex temporal evolution of both mean and variability  
- Need to predict both typical and extreme force scenarios  
- Critical safety implications requiring proper uncertainty bounds

### Our approach: distributional GAMs with functional coefficients

The `ffc` package treats both location and scale as smooth functions that evolve over time. By combining [`mgcv`](https://cran.r-project.org/package=mgcv) distributional families with functional regression, we can:

- Model time-varying mean acceleration trends  
- Capture evolving variance patterns throughout crash sequences    
- Generate probabilistic forecasts with parameter-specific uncertainty  
- Validate predictions using rolling forecast techniques  

## Data exploration

We'll use the classic motorcycle crash dataset from [`MASS`](https://cran.r-project.org/package=MASS), representing head acceleration measurements during simulated motorcycle crashes:

```{r data-overview}
data(mcycle, package = "MASS")
mcycle$index <- 1:NROW(mcycle)

# Check data structure
glimpse(mcycle)
```

### Visualizing acceleration patterns

```{r acceleration-patterns, fig.cap="Head acceleration measurements showing clear heteroskedasticity over time."}
ggplot(mcycle, aes(x = index, y = accel)) +
  geom_point(alpha = 0.7, size = 2) +
  geom_line() +
  geom_vline(xintercept = 110, linetype = "dashed", color = "darkred", alpha = 0.7) +
  labs(
    x = "Time Index", 
    y = "Head Acceleration",
    title = "Motorcycle crash data: heteroskedastic acceleration patterns"
  )
```

The data shows low variance before impact, extreme variance during the crash, and moderate variance in the rebound phase.

### Identifying variance patterns

Let's examine how variance changes across different phases of the crash sequence:

```{r variance-exploration, fig.cap="Moving variance reveals dramatic changes in acceleration variability over time."}
# Calculate moving variance with overlapping windows
window_size <- 15
mcycle$moving_var <- NA

for (i in (window_size + 1):(nrow(mcycle) - window_size)) {
  window_data <- mcycle$accel[(i - window_size):(i + window_size)]
  mcycle$moving_var[i] <- var(window_data, na.rm = TRUE)
}

ggplot(mcycle, aes(x = index)) +
  geom_line(aes(y = moving_var), color = "darkred", linewidth = 1.2) +
  geom_point(aes(y = moving_var), color = "darkred", alpha = 0.7) +
  labs(
    x = "Time Index",
    y = "Moving variance",
    title = "Time-varying variance in motorcycle crash acceleration"
  )
```

The moving variance peaks dramatically during the crash phase, confirming that constant variance assumptions would be inappropriate for this data.

## Modeling with distributional GAMs

### Train-test split for validation

We'll use early crash data for training and reserve later impact phases for validation:

```{r data-split}
mcycle_train <- mcycle |>
  dplyr::filter(index < 110)
mcycle_test <- mcycle |>
  dplyr::filter(index >= 110)
```

### The distributional model specification

Now let's fit a model that will allow us to forecast changes in both the mean *and* the variance. The key innovation is using [`gaulss()`](https://rdrr.io/cran/mgcv/man/gaulss.html) to model both location and scale parameters with functional time series:

```{r fit-model}
mcycle_gaulss_model <- ffc_gam(
  list(
    # Location parameter: time-varying mean acceleration  
    accel ~ fts(index, mean_only = TRUE, time_k = 25),
    
    # Scale parameter: time-varying variance
    ~ fts(index, mean_only = TRUE, time_k = 25)
  ),
  family = gaulss(),
  data = mcycle_train,
  time = "index"
)
```

### Understanding the model structure

```{r model-summary}
summary(mcycle_gaulss_model)
```

The model decomposes crash dynamics into:  

1. **Location parameter**: Smooth time-varying mean acceleration    
2. **Scale parameter**: Time-varying standard deviation modeling heteroskedasticity    

The [`gaulss()`](https://rdrr.io/cran/mgcv/man/gaulss.html) family uses log-link for the scale parameter, ensuring positive variance estimates throughout the crash sequence.

## Model diagnostics and interpretation

### Visualizing fitted trends and variance

We can examine how the model captures both mean trends and changing variance:

```{r fitted-patterns, fig.cap="Fitted location and scale parameters reveal distinct temporal patterns in crash dynamics."}
# Extract time-varying coefficients for both parameters
fts_results <- fts_coefs(mcycle_gaulss_model, summary = FALSE)

autoplot(fts_results) +
  labs(
    title = "Time-varying distributional parameters",
    x = "Time Index",
    y = "Coefficient Value"
  )
```

The location parameter captures the mean acceleration trajectory while the scale parameter adapts to varying uncertainty levels throughout the crash sequence.

### Extracting parameter-specific coefficients

The functional coefficients reveal the underlying dynamics of each distributional parameter:

```{r extract-coefficients}
# View coefficient structure
fts_results

# Summary statistics by parameter
fts_results |>
  as_tibble() |>
  group_by(.parameter, .basis) |>
  summarise(
    mean_coef = mean(.estimate),
    sd_coef = sd(.estimate),
    .groups = "drop"
  )
```

## Forecasting distributional models

### Single forecast demonstration

Generate forecasts that provide both mean predictions and uncertainty intervals based on the evolving variance structure:

```{r single-forecast}
fc_single <- forecast(
  mcycle_gaulss_model,
  newdata = mcycle_test,
  model = "ENS",
  mean_model = "ENS"
)

# Examine forecast structure
fc_single
```

### Visualizing distributional forecasts

```{r forecast-visualization, fig.cap="Distributional forecasts capture both mean trends and evolving uncertainty from the time-varying scale parameter."}
# Combine training and forecast data for visualization
forecast_plot_data <- mcycle_train |>
  as_tibble() |>
  mutate(type = "observed") |>
  bind_rows(
    mcycle_test |>
      as_tibble() |>
      bind_cols(fc_single) |>
      mutate(type = "forecast")
  )

ggplot(forecast_plot_data, aes(x = index, y = accel)) +
  geom_point(data = filter(forecast_plot_data, type == "observed"),
             alpha = 0.7, size = 2) +
  geom_ribbon(data = filter(forecast_plot_data, type == "forecast"),
              aes(ymin = .q2.5, ymax = .q97.5),
              fill = "darkred", alpha = 0.2) +
  geom_ribbon(data = filter(forecast_plot_data, type == "forecast"),
              aes(ymin = .q10, ymax = .q90),
              fill = "darkred", alpha = 0.3) +
  geom_line(data = filter(forecast_plot_data, type == "forecast"),
            aes(y = .estimate),
            colour = "darkred", linewidth = 1.2) +
  geom_point(data = filter(forecast_plot_data, type == "forecast"),
             color = "black", size = 2) +
  labs(
    title = "Distributional GAM forecasts for motorcycle crash acceleration",
    x = "Time Index", 
    y = "Head Acceleration"
  )
```

The widening prediction intervals in the test period reflect increasing uncertainty as we forecast further from the training data, a natural consequence of parameter extrapolation.

## Coefficient forecast inspection

We can also forecast the functional coefficients themselves to understand how the underlying parameters evolve:

```{r coefficient-forecasting, fig.cap="Forecasted functional coefficients show parameter-specific evolution patterns with quantified uncertainty."}
# Forecast the coefficients to the test period
coef_forecast_raw <- forecast(
  fts_results,
  h = nrow(mcycle_test),
  model = "ENS"
)

# Summarize coefficient forecasts
coef_forecast <- coef_forecast_raw |>
  as_tibble() |>
  group_by(.basis, .time) |>
  summarise(
    .estimate = mean(.sim),
    .q2.5 = quantile(.sim, 0.025),
    .q97.5 = quantile(.sim, 0.975),
    .groups = "drop"
  )

# Summarize training coefficients
fts_coefs_summary <- fts_results |>
  as_tibble() |>
  group_by(.basis, .time) |>
  summarise(
    .estimate = mean(.estimate),
    .groups = "drop"
  )

# Visualize coefficient evolution and forecasts
ggplot() +
  geom_line(data = fts_coefs_summary,
            aes(x = .time, y = .estimate, color = .basis),
            linewidth = 1) +
  geom_ribbon(data = coef_forecast,
              aes(x = .time, ymin = .q2.5, ymax = .q97.5, fill = .basis),
              alpha = 0.2) +
  geom_line(data = coef_forecast,
            aes(x = .time, y = .estimate, color = .basis),
            linewidth = 1.2) +
  facet_wrap(~ .basis, scales = "free_y") +
  labs(
    title = "Functional coefficients: training vs forecasted",
    x = "Time Index", 
    y = "Coefficient Value"
  ) +
  theme(legend.position = "none")
```

The forecasts for both parameters reflect the underlying nonlinear dynamics captured by the exponential smoothing and random walk ensemble model.

## Rolling forecast evaluation

### Understanding rolling forecast evaluation

[Rolling forecast evaluation](https://otexts.com/fpp3/tscv.html), also known as time series cross-validation, provides a more robust assessment of model performance than traditional train-test splits. Instead of evaluating predictions from a single time point, this approach tests how well a model performs when making forecasts from many different origins throughout the time series. This mimics real-world forecasting scenarios where we continuously update our models with new data and generate fresh predictions.
  
The method works by sliding a fixed-size training window through the time series. At each position, we fit the model using only the data within that window, then generate forecasts for a specified number of steps ahead (the forecast horizon). By advancing the window position systematically (determined by the step size), we obtain multiple sets of forecasts that can be evaluated against the actual observed values. This reveals whether our model maintains consistent performance across different time periods and data conditions.
  
For distributional models like ours, rolling evaluation is particularly valuable because it tests whether prediction intervals remain well-calibrated throughout the entire time series. In safety-critical applications such as crash analysis, we need confidence that our uncertainty estimates are reliable not just on average, but consistently across all phases of the crash timeline.

### Rolling forecast parameters

```{r rolling-setup}
# Use 70 observations for each training window - enough data to estimate
# time-varying parameters while allowing multiple forecast origins
window_size <- 70

# Predict 5 steps ahead from each origin - tests short-term accuracy
# relevant for crash dynamics without extending into highly uncertain territory  
forecast_horizon <- 5

# Advance forecast origin by 5 steps between evaluations - balances
# computational cost with evaluation thoroughness
step_size <- 5

# Calculate where each forecast origin will be positioned
max_start <- nrow(mcycle) - forecast_horizon
forecast_starts <- seq(1, max(1, max_start - window_size), by = step_size)
```

The choice of window size reflects a trade-off between having enough data to reliably estimate model parameters and maintaining enough forecast origins for robust evaluation. Our window of 50 observations captures sufficient crash dynamics while the step size of 10 provides reasonable coverage of the timeline without excessive computational burden. The 10-step forecast horizon tests the model's ability to predict the immediate future, which is most relevant for understanding crash dynamics where conditions can change rapidly.

### Executing rolling forecasts

The rolling forecast loop systematically moves through the time series, fitting a fresh model at each origin and generating predictions for the subsequent time points. This process simulates how forecasting works in practice, where we periodically retrain our models with the latest available data.

```{r rolling-forecasts}
# List to accumulate results from each forecast origin
rolling_results <- list()

# Loop through each forecast origin position
for (i in seq_along(forecast_starts)) {
  # Define the training window boundaries
  start_idx <- forecast_starts[i]
  end_idx <- min(start_idx + window_size - 1, nrow(mcycle))

  # Extract training data for this window
  train_data <- mcycle[start_idx:end_idx, ]
  
  # Define the test period immediately following the training window
  test_start <- end_idx + 1
  test_end <- min(test_start + forecast_horizon - 1, nrow(mcycle))

  # Only proceed if we have enough data for the full test period
  if (test_end <= nrow(mcycle)) {
    test_data <- mcycle[test_start:test_end, ]

    # Fit a distributional model to the training window
    # Using mean_only = TRUE for computational efficiency in the loop
    roll_model <- ffc_gam(
      list(
        accel ~ fts(index, mean_only = TRUE, time_k = 10),
        ~ fts(index, mean_only = TRUE, time_k = 10)
      ),
      family = gaulss(),
      data = train_data,
      time = "index"
    )

    # Generate forecasts for the test period using ensemble method
    roll_forecast <- forecast(
      roll_model,
      newdata = test_data,
      model = "ENS"
    )

    # Combine actual values with predictions and add tracking metadata
    rolling_results[[i]] <- test_data |>
      bind_cols(roll_forecast) |>
      mutate(
        forecast_origin = i,
        train_start = start_idx,
        train_end = end_idx,
        horizon = 1:nrow(test_data)
      )
  }
}

# Combine all forecast results into a single data frame for analysis
rolling_forecasts <- bind_rows(rolling_results)
```

Each iteration of this loop represents a realistic forecasting scenario where we have historical data up to a certain point (the training window) and must predict what happens next. The metadata we track allows us to analyze how performance varies by forecast origin and horizon.

## Rolling forecast performance analysis

### Forecast accuracy metrics

To evaluate our distributional forecasts comprehensively, we calculate both point forecast accuracy measures and [coverage statistics](https://otexts.com/fpp3/distaccuracy.html) for the prediction intervals. Coverage refers to the proportion of actual observations that fall within the predicted intervals. A well-calibrated 95% prediction interval should contain the true value approximately 95% of the time across many forecasts. If coverage is substantially lower, the model is overconfident; if higher, it is being unnecessarily conservative.

```{r performance-analysis}
# Calculate comprehensive performance metrics for each forecast
rolling_forecasts <- rolling_forecasts |>
  mutate(
    # Point forecast errors
    forecast_error = accel - .estimate,
    abs_error = abs(forecast_error),
    squared_error = forecast_error^2,
    
    # Coverage indicators: TRUE if actual value falls within interval
    coverage_95 = (accel >= .q2.5) & (accel <= .q97.5),
    coverage_80 = (accel >= .q10) & (accel <= .q90),
    
    # Interval widths to assess uncertainty magnitude
    interval_width_95 = .q97.5 - .q2.5,
    interval_width_80 = .q90 - .q10
  )

# Performance by forecast horizon
horizon_stats <- rolling_forecasts |>
  group_by(horizon) |>
  summarise(
    n_forecasts = n(),
    mae = mean(abs_error, na.rm = TRUE),
    rmse = sqrt(mean(squared_error, na.rm = TRUE)),
    coverage_95 = mean(coverage_95, na.rm = TRUE),
    coverage_80 = mean(coverage_80, na.rm = TRUE),
    avg_width_95 = mean(interval_width_95, na.rm = TRUE),
    avg_width_80 = mean(interval_width_80, na.rm = TRUE),
    .groups = 'drop'
  )

horizon_stats

# Overall performance summary  
overall_stats <- rolling_forecasts |>
  summarise(
    total_forecasts = n(),
    overall_mae = mean(abs_error, na.rm = TRUE),
    overall_rmse = sqrt(mean(squared_error, na.rm = TRUE)),
    overall_coverage_95 = mean(coverage_95, na.rm = TRUE),
    overall_coverage_80 = mean(coverage_80, na.rm = TRUE)
  )

cat("- 95% coverage:", round(overall_stats$overall_coverage_95 * 100, 1), "%\n")
cat("- 80% coverage:", round(overall_stats$overall_coverage_80 * 100, 1), "%\n")
```

### Rolling forecast visualization

```{r rolling-visualization, fig.cap="Rolling forecast evaluation reveals consistent prediction performance across different crash phases."}
# Visualize rolling forecasts over the full time series
ggplot() +
  geom_point(data = mcycle, aes(x = index, y = accel),
             alpha = 0.4, size = 1) +
  geom_line(data = mcycle, aes(x = index, y = accel),
             alpha = 0.4) +
  geom_point(data = rolling_forecasts,
             aes(x = index, y = .estimate),
             color = "darkred", size = 1.5, alpha = 0.8) +
  geom_errorbar(data = rolling_forecasts,
                aes(x = index, ymin = .q10, ymax = .q90),
                color = "darkred", alpha = 0.6, width = 0.5) +
  geom_segment(data = rolling_forecasts,
               aes(x = index, xend = index, y = accel, yend = .estimate),
               color = "darkblue", alpha = 0.3, linetype = "dashed") +
  labs(
    title = "Rolling forecast evaluation across crash timeline",
    x = "Time Index", 
    y = "Head Acceleration"
  )
```

The plot shows forecasts (red points) with 80% prediction intervals capturing the observed values across diverse crash phases, demonstrating consistent model performance.

### Coverage evolution analysis

```{r coverage-evolution, fig.cap="Cumulative coverage rates demonstrate improved coverage of prediction intervals throughout the evaluation."}
# Track coverage evolution over evaluation period
coverage_data <- rolling_forecasts |>
  arrange(index) |>
  mutate(
    running_coverage_95 = cumsum(coverage_95) / row_number(),
    running_coverage_80 = cumsum(coverage_80) / row_number()
  )

ggplot(coverage_data, aes(x = index)) +
  geom_line(aes(y = running_coverage_95), color = "darkred", linewidth = 1.2) +
  geom_line(aes(y = running_coverage_80), color = "darkblue", linewidth = 1.2) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkred", alpha = 0.7) +
  geom_hline(yintercept = 0.80, linetype = "dashed", color = "darkblue", alpha = 0.7) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Cumulative coverage rates validate interval calibration",
    x = "Time Index",
    y = "Cumulative Coverage Rate"
  )
```

The cumulative coverage rates fluctuate across the time index, revealing how the forecasts did not anticipate the initial, major rise in both acceleration and the variance. Once the models had seen that period, the forecasts improved substantially.

## Key insights and best practices

### When to use distributional regression

Distributional regression with `ffc` is essential when:  

- Data exhibits clear heteroskedasticity (changing variance over time)  
- Both mean trends and uncertainty evolution matter for interpretation  
- Risk assessment requires proper uncertainty bounds  
- Traditional constant-variance assumptions are violated  

Key implementation considerations:

- Use list formula syntax: `list(response ~ fts(...), ~ fts(...))`    
- Choose appropriate distributional families   ([`gaulss()`](https://rdrr.io/cran/mgcv/man/gaulss.html), [`twlss()`](https://rdrr.io/cran/mgcv/man/twlss.html), [`betar()`](https://rdrr.io/cran/mgcv/man/betar.html))  
- Scale parameter automatically uses log-link for positivity  
- Different `time_k` values can be used for different parameters  

### Distributional forecasting advantages

The time-varying distributional approach excels when:  

- Traditional homoskedastic models miss variance patterns  
- Parameter-specific uncertainty quantification is needed    
- Rolling validation reveals model robustness across conditions  
- Safety applications require conservative interval estimation  

For detailed guidance on distributional families in [`mgcv`](https://cran.r-project.org/package=mgcv), see [Wood (2017)](https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331).

## Conclusion

This vignette demonstrated advanced distributional regression techniques for motorcycle crash data:
  
- Time-varying location and scale parameters capture evolving crash dynamics  
- Functional time series coefficients provide interpretable parameter evolution  
- Rolling forecast evaluation ensures robust model validation  
- Proper uncertainty quantification enables safety-critical applications  

The `ffc` package integrates distributional modeling seamlessly with functional forecasting:
- List formula syntax for multi-parameter specifications  
- Parameter-specific coefficient extraction and forecasting    
- Comprehensive validation through rolling forecast techniques  
- Integration with [`mgcv`](https://cran.r-project.org/package=mgcv) distributional families

### Further reading

- Wood (2017): [Generalized Additive Models: An Introduction with R](https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331)  
- Rigby & Stasinopoulos (2005): [Generalized additive models for location, scale and shape](https://doi.org/10.1111/j.1467-9876.2005.00510.x)    
- Hyndman & Athanasopoulos (2021): [Forecasting: Principles and Practice](https://otexts.com/fpp3/)  
- [mgcv distributional families documentation](https://rdrr.io/cran/mgcv/man/family.mgcv.html)
